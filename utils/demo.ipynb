{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP-JAX demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "from functools import partial\n",
    "from io import BytesIO\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import requests\n",
    "from flax.training import checkpoints\n",
    "from flax.traverse_util import flatten_dict\n",
    "from jax.experimental.mesh_utils import create_device_mesh\n",
    "from jax.experimental.pjit import pjit\n",
    "from jax.sharding import Mesh, PartitionSpec\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from clip_jax import CLIPModel\n",
    "from clip_jax.data import image_to_logits\n",
    "from clip_jax.partitions import logical_axis_rules\n",
    "from clip_jax.utils import count_params, load_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a config\n",
    "model_path = \"../configs/small-patch16.json\"\n",
    "config = load_config(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = CLIPModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save loaded config (adds potential missing defaults)\n",
    "config = {k: v for k, v in asdict(model).items() if k not in [\"parent\", \"name\"]}\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    f.write(json.dumps(config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model_inputs = model.init_inputs(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display summary\n",
    "tabulation = model.tabulate(\n",
    "    **model_inputs, console_kwargs={\"width\": 400, \"force_terminal\": False, \"force_jupyter\": False}\n",
    ")\n",
    "# write to a file (too long to be displayed in the notebook)\n",
    "with open(\"summary.md\", \"w\") as f:\n",
    "    f.write(tabulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get logical params\n",
    "logical_params = jax.eval_shape(lambda inputs: model.init(**inputs), model_inputs)[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parameters\n",
    "print(f\"Number of parameters: {count_params(logical_params):,}\")\n",
    "for k, v in logical_params.items():\n",
    "    print(f\"{k}: {count_params(v):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get logical spec\n",
    "logical_spec = nn.get_partition_spec(logical_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all logical axes\n",
    "logical_axes = {i for s in flatten_dict(logical_spec).values() for i in s}\n",
    "logical_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get partition spec\n",
    "rules = logical_axis_rules(activation_partitioning_dims=1, parameter_partitioning_dims=1)\n",
    "params_spec = nn.logical_to_mesh(logical_spec, rules)\n",
    "data_spec = PartitionSpec(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mesh\n",
    "mp_devices = 1\n",
    "dp_devices = jax.local_device_count() // 1\n",
    "dev_mesh = create_device_mesh((dp_devices, 1))\n",
    "mesh = Mesh(dev_mesh, (\"data\", \"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "\n",
    "\n",
    "@partial(pjit, in_shardings=None, out_shardings=params_spec)\n",
    "def init_params():\n",
    "    return model.init(**model_inputs)[\"params\"]\n",
    "\n",
    "\n",
    "with mesh:\n",
    "    params = init_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer_name = \"openai/clip-vit-base-patch32\"\n",
    "tokenizer_name = \"../training/craiyon_tokenizer\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_path = \"gs://craiyon_models_us_central2/clip/20230430112259\"\n",
    "config = load_config(f\"{model_path}/config.json\")\n",
    "model = CLIPModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model_inputs = model.init_inputs(rng)\n",
    "logical_shape = jax.eval_shape(model.init, **model_inputs)[\"params\"]\n",
    "params = jax.tree_map(lambda x: jnp.zeros(x.shape, dtype=x.dtype), logical_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore checkpoint\n",
    "params = checkpoints.restore_checkpoint(model_path, target=params, prefix=\"model_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference functions\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_text_features(input_ids, attention_mask, params):\n",
    "    return model.apply(\n",
    "        {\"params\": params}, input_ids=input_ids, attention_mask=attention_mask, method=model.get_text_features\n",
    "    )[\"text_embeds\"]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_image_features(pixel_values, params):\n",
    "    return model.apply({\"params\": params}, pixel_values=pixel_values, method=model.get_image_features)[\"image_embeds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data\n",
    "img_url = \"https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=0.752xw:1.00xh;0.175xw,0&resize=1200:*\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image inference\n",
    "pixel_values = image_to_logits(img)\n",
    "pixel_values = pixel_values[np.newaxis, ...]\n",
    "img_embeds = get_image_features(pixel_values, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text inference\n",
    "text = \"a dog\"\n",
    "text_inputs = tokenizer(\n",
    "    text, padding=\"max_length\", truncation=True, max_length=config[\"text_config\"][\"max_length\"], return_tensors=\"np\"\n",
    ")\n",
    "text_embeds = get_text_features(\n",
    "    input_ids=text_inputs[\"input_ids\"], attention_mask=text_inputs[\"attention_mask\"], params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similarity\n",
    "similarity = jnp.matmul(img_embeds, text_embeds.T)\n",
    "similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
