{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPPA demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases how to use a CAPPAâ€¯model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from io import BytesIO\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import orbax\n",
    "import requests\n",
    "import wandb\n",
    "from flax.training import orbax_utils\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from clip_jax import CLIPModel\n",
    "from clip_jax.data import Dataset, image_to_logits, logits_to_image\n",
    "from clip_jax.utils import load_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer_name = \"xxxx\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "config_name = \"entity/project/config-run_id:latest\"\n",
    "config = load_config(config_name)\n",
    "model = CLIPModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "logical_shape = jax.eval_shape(lambda rng: model.init_weights(rng), rng)[\"params\"]\n",
    "params = jax.tree_map(lambda x: jnp.zeros(x.shape, dtype=x.dtype), logical_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model checkpoint\n",
    "api = wandb.Api()\n",
    "artifact = api.artifact(config_name)\n",
    "step = artifact.metadata[\"step\"]\n",
    "model_path = artifact.metadata[\"output_dir\"]\n",
    "model_path, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore checkpoint\n",
    "ckpt = {\"params\": params}\n",
    "restore_args = orbax_utils.restore_args_from_target(ckpt)\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "orbax_options = orbax.checkpoint.CheckpointManagerOptions()\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(model_path, orbax_checkpointer, orbax_options)\n",
    "ckpt = checkpoint_manager.restore(step, ckpt, restore_kwargs={\"restore_args\": restore_args, \"transforms\": {}})\n",
    "params = ckpt[\"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(\n",
    "    jax.jit,\n",
    "    static_argnames=(\"num_beams\", \"do_sample\", \"temperature\", \"top_p\", \"top_k\", \"max_length\", \"num_return_sequences\"),\n",
    ")\n",
    "def generate_caption(pixel_values, *args, **kwargs):\n",
    "    return model.generate(pixel_values, *args, **kwargs)\n",
    "\n",
    "\n",
    "def caption(*args, **kwargs):\n",
    "    outputs = generate_caption(*args, **kwargs)\n",
    "    res = outputs.sequences\n",
    "    return tokenizer.batch_decode(res, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data\n",
    "img_url = \"https://pics.craiyon.com/2023-06-23/3b050d2ebfcc47e7a2d25265ffc6b588.webp\"\n",
    "\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.resize((256, 256))\n",
    "img = img.convert(\"RGB\")\n",
    "# image inference\n",
    "pixel_values = image_to_logits(img)\n",
    "pixel_values = pixel_values[np.newaxis, ...]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption(pixel_values, params=params, num_beams=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption(pixel_values, params=params, do_sample=True, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption(pixel_values, params=params, num_beams=4, num_return_sequences=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_folder = \"xxx\"  # need to follow same format as for training, at least tfrecords\n",
    "ds = Dataset(train_folder=ds_folder, train_batch_size=1, image_crop_resize=256).train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values, captions = next(ds)\n",
    "generated_captions = caption(pixel_values, params=params, num_beams=4)\n",
    "img = Image.fromarray(logits_to_image(pixel_values[0]))\n",
    "display(img)\n",
    "print(\"caption:\", captions[0].decode(\"utf-8\"))\n",
    "print(\"generated caption:\", generated_captions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa3d2ab134fae865f4add8129f6d39439f1593eafeb08333862636037ecdb592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
