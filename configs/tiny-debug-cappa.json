{
  "text_config": {
    "dtype": "float32",
    "activations": ["gelu", "linear"],
    "normalize_qk": false,
    "use_bias": false,
    "force_scale": false,
    "attention_dropout": 0.0,
    "mlp_dropout_rate": 0.0,
    "unroll": 100,
    "gradient_checkpointing": true,
    "eos_token_id": 2,
    "mask_token_id": 4,
    "masked_pred_prob": 0.75,
    "is_decoder": true,
    "vocab_size": 50000,
    "hidden_size": 384,
    "max_length": 64,
    "num_layers": 4,
    "use_rmsnorm": true,
    "ln_type": "normformer",
    "num_heads": 8,
    "position_embedding_type": "rotary",
    "use_causal_mask": true,
    "mlp_dim": 768
  },
  "vision_config": {
    "position_embedding_type": "learnt",
    "position_embedding_shape": null,
    "position_embedding_factorized": false,
    "dtype": "float32",
    "activations": ["gelu", "linear"],
    "normalize_qk": false,
    "use_bias": false,
    "force_scale": false,
    "attention_dropout": 0.0,
    "mlp_dropout_rate": 0.0,
    "pool_type": null,
    "unroll": 100,
    "registers": 0,
    "gradient_checkpointing": true,
    "image_size": 256,
    "hidden_size": 384,
    "patch_size": 16,
    "num_layers": 8,
    "use_rmsnorm": true,
    "ln_type": "normformer",
    "num_heads": 8,
    "use_causal_mask": false,
    "mlp_dim": 768
  },
  "projection_dim": 512,
  "logit_scale_init_value": 10.0,
  "logit_bias_init_value": -10.0,
  "dtype": "float32"
}
